import streamlit as st
import pandas as pd
import numpy as np
import os
from sklearn.metrics.pairwise import cosine_similarity

st.set_page_config(page_title="AI Movie Recommender", layout="wide")

# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Path ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö Docker Volume
BASE_PATH = "/app"
RESULT_PATH = os.path.join(BASE_PATH, "output/final_recommend")
MOVIE_LIST_PATH = os.path.join(BASE_PATH, "output/movie_list")
MODEL_FACTORS_PATH = os.path.join(BASE_PATH, "model/als_model/itemFactors")

def load_csv(path):
    if os.path.exists(path):
        files = [f for f in os.listdir(path) if f.endswith('.csv')]
        if files: return pd.read_csv(os.path.join(path, files[0]))
    return None

def load_factors(path):
    if os.path.exists(path):
        try: return pd.read_parquet(path, engine='pyarrow')
        except: return None
    return None

df_recs = load_csv(RESULT_PATH)
df_movies = load_csv(MOVIE_LIST_PATH)
df_factors = load_factors(MODEL_FACTORS_PATH)

st.title("üé¨ AI Movie Recommender (Hybrid System)")

if df_movies is not None:
    # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 1: Batch Recommend
    st.subheader("üîç ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏£‡∏≤‡∏¢‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏• (Batch)")
    if df_recs is not None:
        user_id = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å User ID:", sorted(df_recs['userId'].unique()))
        if st.button("‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥"):
            st.success(df_recs[df_recs['userId'] == user_id]['recommended_movies'].values[0])

    st.divider()

    # ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: Similarity Calculation
    st.subheader("üéûÔ∏è ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏ô‡∏±‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏Ñ‡∏µ‡∏¢‡∏á (Real-time AI)")
    movie_choice = st.selectbox("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏´‡∏ô‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ä‡∏≠‡∏ö:", df_movies['title'].sort_values().unique())
    
    if movie_choice:
        target_id = df_movies[df_movies['title'] == movie_choice]['movieId'].values[0]
        
        if df_factors is not None:
            target_row = df_factors[df_factors['id'] == target_id]
            if not target_row.empty:
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢
                target_v = np.array(target_row['features'].values[0]).reshape(1, -1)
                all_vectors = np.array([np.array(x) for x in df_factors['features'].values])
                all_ids = df_factors['id'].values
                
                # 
                scores = cosine_similarity(target_v, all_vectors)[0]
                top_idx = scores.argsort()[-6:-1][::-1] # ‡πÄ‡∏≠‡∏≤ 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á
                
                st.write("### ü§ñ ‡∏´‡∏ô‡∏±‡∏á‡∏ó‡∏µ‡πà AI ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏à‡∏£‡∏¥‡∏á‡πÜ:")
                for i in top_idx:
                    sim_id = all_ids[i]
                    m_title = df_movies[df_movies['movieId'] == sim_id]['title'].values[0]
                    st.write(f"‚≠ê **{m_title}** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢: {scores[i]:.2%})")
            else:
                st.warning("‡∏´‡∏ô‡∏±‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ô‡∏µ‡πâ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Model AI")
else:
    st.error("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏£‡∏±‡∏ô Spark ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏Å‡πà‡∏≠‡∏ô")